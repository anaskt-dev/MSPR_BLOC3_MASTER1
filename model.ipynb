{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c6b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(r\"C:\\Users\\kotoub.a\\AppData\\Roaming\\Python\\Python312\\site-packages\")\n",
    "import duckdb, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DB dans le même dossier que ce notebook ? sinon ajuste ce chemin absolu\n",
    "BASE_DIR = Path.cwd()  # <- par défaut: dossier du notebook\n",
    "DB_PATH  = BASE_DIR / \"warehouse.duckdb\"\n",
    "\n",
    "# Si ton ETL a écrit le DW ailleurs, **mets le chemin absolu** ci-dessous :\n",
    "# DB_PATH = Path(r\"D:\\MSPR_CODE\\MSPR_BLOC3_MASTER1\\etl\\warehouse.duckdb\")\n",
    "\n",
    "print(\"DuckDB utilisé :\", DB_PATH.resolve())\n",
    "\n",
    "con = duckdb.connect(str(DB_PATH))\n",
    "con.execute(\"PRAGMA database_list\").df()  # vérif du fichier réellement ouvert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c429441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister les tables\n",
    "con.execute(\"SHOW TABLES\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décrire une table (ex: fact_election_tour1)\n",
    "con.execute(\"DESCRIBE fact_election_tour1\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ Adapte les noms de colonnes si besoin (regarde la cellule \"DESCRIBE\")\n",
    "QUERY = \"\"\"\n",
    "WITH base AS (\n",
    "    SELECT\n",
    "        t1.code_departement,\n",
    "        t1.libelle_departement,\n",
    "        t1.inscrits,\n",
    "        t1.votants,\n",
    "        t1.blancs,\n",
    "        t1.nuls,\n",
    "        t1.exprimes,\n",
    "        c.taux_chomage\n",
    "    FROM fact_election_tour1 AS t1\n",
    "    LEFT JOIN fact_chomage AS c\n",
    "        ON c.code_departement = t1.code_departement\n",
    "),\n",
    "feat AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        CAST(votants AS DOUBLE)/NULLIF(inscrits,0)    AS taux_participation,\n",
    "        CAST(blancs  AS DOUBLE)/NULLIF(votants ,0)    AS taux_blancs_sur_votants,\n",
    "        CAST(nuls    AS DOUBLE)/NULLIF(votants ,0)    AS taux_nuls_sur_votants,\n",
    "        CAST(exprimes AS DOUBLE)/NULLIF(votants ,0)   AS taux_exprimes_sur_votants\n",
    "    FROM base\n",
    ")\n",
    "SELECT *\n",
    "FROM feat\n",
    "WHERE inscrits IS NOT NULL AND votants IS NOT NULL AND exprimes IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "df = con.execute(QUERY).df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34639a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# - Si tu crées une cible binaire: participation > 60% ?\n",
    "df[\"target\"] = (df[\"taux_participation\"] >= 0.60).astype(int)\n",
    "\n",
    "# Features numériques candidates (adapte selon ton besoin)\n",
    "feature_cols = [\n",
    "    \"inscrits\",\"votants\",\"blancs\",\"nuls\",\"exprimes\",\n",
    "    \"taux_chomage\",\"taux_participation\",\"taux_blancs_sur_votants\",\n",
    "    \"taux_nuls_sur_votants\",\"taux_exprimes_sur_votants\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[\"target\"].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ee441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=200, n_jobs=None))\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = pipe.predict(X_test)\n",
    "y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "MODEL_PATH = BASE_DIR / \"model_participation.joblib\"\n",
    "dump(pipe, MODEL_PATH)\n",
    "print(\"Modèle sauvegardé :\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "pipe2 = load(MODEL_PATH)\n",
    "\n",
    "# Prédiction sur 5 lignes pour vérifier que tout marche\n",
    "pipe2.predict(X_test.iloc[:5]), pipe2.predict_proba(X_test.iloc[:5])[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
